# Technical Debt Review - McMocknald Order Kiosk Project

**Review Date:** 2025-10-24
**Review Time:** 02:15:05
**Reviewer:** Claude Code (Technical Debt Sub-Agent)
**Project:** McMocknald Order Kiosk System
**Go Version:** 1.25.3

---

## Executive Summary

### Summary
**REQUIRES CHANGES** - Critical build-blocking issues detected that prevent compilation and deployment.

The McMocknald Order Kiosk project demonstrates strong architectural foundations with Clean Architecture, SOLID principles, and proper abstraction patterns. However, **critical technical debt has been identified that completely blocks the build process**, along with security concerns, performance issues, and documentation gaps that must be addressed before production deployment.

**Critical Issues Found:** 1
**High Priority Issues:** 4
**Medium Priority Issues:** 6
**Low Priority Issues:** 3

---

## CRITICAL ISSUES - BUILD BLOCKERS

### 1. Consistently Failing Build Process - Import Path Mismatch

**Severity:** CRITICAL
**Category:** Build Process Failure
**Impact:** Complete build failure - application cannot compile

#### Issue Description

The codebase contains a **critical module path mismatch** between `go.mod` and import statements across 14 source files. This causes complete build failure.

**Module declared in go.mod:**
```
module mcmocknald-order-kiosk
```

**Import paths used in code:**
```go
import "github.com/kazleow/mcmocknald-order-kiosk/internal/service"
```

#### Affected Files (14 files)

1. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\order_service.go` (Lines 8-10)
2. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\cook_service.go` (Lines 9-11)
3. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\order_service_test.go` (Lines 10-13)
4. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\handler\order_handler.go` (Line 8)
5. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\handler\cook_handler.go` (Line 8)
6. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\postgres\user_repository.go` (Line 9)
7. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\postgres\order_repository.go` (Line 9)
8. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\postgres\food_repository.go` (Line 9)
9. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\postgres\role_repository.go` (Line 9)
10. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\memory\user_repository.go` (Line 9)
11. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\memory\order_repository.go` (Line 9)
12. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\memory\food_repository.go` (Line 9)
13. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\memory\role_repository.go` (Line 9)
14. `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\pkg\queue\priority_queue.go` (Line 6)

#### Build Error Output
```
internal\handler\cook_handler.go:8:2: no required module provides package github.com/kazleow/mcmocknald-order-kiosk/internal/service
internal\infrastructure\memory\food_repository.go:9:2: no required module provides package github.com/kazleow/mcmocknald-order-kiosk/internal/domain
internal\service\cook_service.go:10:2: no required module provides package github.com/kazleow/mcmocknald-order-kiosk/internal/logger
internal\service\cook_service.go:11:2: no required module provides package github.com/kazleow/mcmocknald-order-kiosk/pkg/queue
```

#### Recommended Fix

**Option 1: Update go.mod (Recommended if publishing to GitHub)**
```go
// go.mod
module github.com/kazleow/mcmocknald-order-kiosk

go 1.25.3
```

**Option 2: Update all import statements (Recommended if keeping local)**

Replace all instances of:
```go
import "github.com/kazleow/mcmocknald-order-kiosk/..."
```

With:
```go
import "mcmocknald-order-kiosk/..."
```

#### Remediation Steps

1. Choose Option 1 or Option 2 based on deployment strategy
2. If Option 1: Update `go.mod` module declaration
3. If Option 2: Use find-replace across all 14 files to update import paths
4. Run `go mod tidy` to validate dependencies
5. Run `go build -o bin/mcmocknald-api cmd/api/main.go` to verify build
6. Run `go test ./...` to ensure tests compile and pass

#### Technical Debt Impact

- **Build:** Complete failure - blocks all compilation
- **Testing:** Cannot run tests
- **Deployment:** Cannot deploy application
- **CI/CD:** All automated builds will fail
- **Developer Experience:** Cannot run locally without manual fixes

---

## HIGH PRIORITY ISSUES

### 2. Credential Exposure Risk - .env File Tracked in Git

**Severity:** HIGH
**Category:** Security - Exposed Credentials
**Impact:** Database credentials and configuration exposed in version control

#### Issue Description

The `.env` file containing sensitive credentials is present in the working directory and appears to be tracked in git (shown in `git status` output as an untracked file, suggesting `.gitignore` is properly configured, but the file exists with actual credentials).

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\.env`

**Exposed Credentials (Lines 10-12):**
```env
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=mcmocknald
```

#### Analysis

**Good News:** `.gitignore` properly excludes `.env` files:
```gitignore
# Line 20-22
.env
.env.local
.env.*.local
```

**Concern:** The `.env` file exists with hardcoded default credentials. While `.env.example` serves as a template, developers may commit actual `.env` if not careful.

#### Recommended Fix

1. **Immediate:** Verify `.env` is NOT committed to git history:
   ```bash
   git log --all --full-history -- .env
   ```

2. **If found in history:** Remove from git history immediately:
   ```bash
   # WARNING: This rewrites git history - coordinate with team
   git filter-branch --force --index-filter \
     "git rm --cached --ignore-unmatch .env" \
     --prune-empty --tag-name-filter cat -- --all
   ```

3. **Best Practice:** Use environment-specific naming:
   - Development: `.env.development` (gitignored)
   - Staging: `.env.staging` (gitignored)
   - Production: Environment variables from deployment platform (never in files)

4. **Documentation:** Add clear warning in README.md:
   ```markdown
   ## Security Notice
   NEVER commit .env files to version control.
   Use .env.example as a template and create your local .env file.
   Production credentials MUST be managed through secure secret management.
   ```

#### Technical Debt Impact

- **Security:** Medium risk if credentials are default/weak, High risk if production credentials
- **Compliance:** May violate security policies requiring secrets management
- **Audit:** Fails security audit requirements for credential handling

---

### 3. Tight Coupling - In-Memory Repository Dependencies

**Severity:** HIGH
**Category:** Tight Coupling
**Impact:** Repository pattern violated with cross-repository dependencies

#### Issue Description

The in-memory `OrderRepository` has **direct dependencies** on `UserRepository` and `FoodRepository`, violating the Dependency Inversion Principle and creating tight coupling between repositories.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\infrastructure\memory\order_repository.go`

**Lines 12-22:**
```go
type OrderRepository struct {
    orders     map[int]*domain.Order       // Map for O(1) lookup by ID
    orderFoods map[int][]int               // Map of order ID to food IDs
    mu         sync.RWMutex                // Protects concurrent access
    nextID     int                         // Auto-increment ID
    userRepo   domain.UserRepository       // Dependency injection for user data ⚠️
    foodRepo   domain.FoodRepository       // Dependency injection for food data ⚠️
}

func NewOrderRepository(userRepo domain.UserRepository, foodRepo domain.FoodRepository) *OrderRepository {
    // Constructor requires other repositories
}
```

**Lines 71-92:** The `GetByID` method directly calls other repositories:
```go
func (r *OrderRepository) GetByID(ctx context.Context, id int) (*domain.Order, error) {
    // ... order lookup ...

    // Tight coupling - repository calling repository ⚠️
    if customer, err := r.userRepo.GetByID(ctx, order.OrderedBy); err == nil {
        order.CustomerName = customer.Name
        order.CustomerRole = customer.Role
    }

    // More tight coupling ⚠️
    if order.AssignedCookUser != nil {
        if cook, err := r.userRepo.GetByID(ctx, *order.AssignedCookUser); err == nil {
            order.CookName = cook.Name
        }
    }

    // Even more tight coupling ⚠️
    if foodIDs, exists := r.orderFoods[id]; exists {
        for _, foodID := range foodIDs {
            if food, err := r.foodRepo.GetByID(ctx, foodID); err == nil {
                foods = append(foods, *food)
            }
        }
    }
}
```

#### Why This Is Problematic

1. **Breaks Repository Pattern:** Repositories should not depend on each other
2. **Circular Dependency Risk:** Creates potential for circular dependencies
3. **Testing Complexity:** Requires mocking multiple repositories to test one
4. **Violates SRP:** Repository doing enrichment work (service layer responsibility)
5. **Inconsistency:** PostgreSQL implementation doesn't have this coupling (uses JOINs)

#### Recommended Fix

**Approach 1: Move Enrichment to Service Layer (Recommended)**

```go
// In OrderRepository - Remove enrichment
func (r *OrderRepository) GetByID(ctx context.Context, id int) (*domain.Order, error) {
    r.mu.RLock()
    defer r.mu.RUnlock()

    order, exists := r.orders[id]
    if !exists {
        return nil, fmt.Errorf("order not found: %d", id)
    }

    // Return basic order without enrichment
    return order, nil
}

// In OrderService - Add enrichment method
func (s *orderService) EnrichOrder(ctx context.Context, order *domain.Order) error {
    // Fetch and populate customer data
    customer, err := s.userRepo.GetByID(ctx, order.OrderedBy)
    if err == nil {
        order.CustomerName = customer.Name
        order.CustomerRole = customer.Role
    }

    // Fetch and populate cook data
    if order.AssignedCookUser != nil {
        cook, err := s.userRepo.GetByID(ctx, *order.AssignedCookUser)
        if err == nil {
            order.CookName = cook.Name
        }
    }

    // Fetch and populate food data
    foods, err := s.foodRepo.GetByOrderID(ctx, order.ID)
    if err == nil {
        order.Foods = foods
    }

    return nil
}
```

**Approach 2: Create Data Transfer Objects (Alternative)**

Create separate DTOs for enriched responses and handle mapping in the service layer.

#### Files Requiring Changes

1. `internal/infrastructure/memory/order_repository.go` - Remove dependencies and enrichment
2. `internal/service/order_service.go` - Add enrichment logic
3. `internal/service/cook_service.go` - Update order handling

#### Technical Debt Impact

- **Maintainability:** Difficult to modify one repository without affecting others
- **Testing:** Increased test complexity and setup overhead
- **Architecture:** Violates Clean Architecture repository isolation
- **Performance:** Unnecessary coupling may lead to N+1 query patterns

---

### 4. Build Process Stability - Missing Context Cancellation

**Severity:** HIGH
**Category:** Build Process / Concurrency
**Impact:** Goroutine leaks in worker pool, potential resource exhaustion

#### Issue Description

The worker pool implementation in `CookService` has a potential goroutine leak due to improper context handling. Workers may not terminate cleanly, leading to resource leaks during shutdown or long-running operations.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\cook_service.go`

**Lines 330-351 - Worker Loop:**
```go
go func() {
    defer s.wg.Done()
    s.logger.Info("Worker started for cook %d", cookID)

    for {
        select {
        case <-worker.stopChan:
            s.logger.Info("Worker stopped for cook %d", cookID)
            return
        case <-s.stopChan:
            s.logger.Info("Worker stopped for cook %d (global stop)", cookID)
            return
        default:
            // Try to accept an order
            _, err := s.AcceptOrder(ctx, cookID)  // ⚠️ ctx never cancelled
            if err != nil {
                time.Sleep(100 * time.Millisecond)
            }
        }
    }
}()
```

#### Problems Identified

1. **No Context Cancellation:** The `ctx` parameter is never checked or cancelled
2. **Blocking Operations:** `AcceptOrder` performs database operations without timeout
3. **Resource Leak:** Workers may hang on database operations during shutdown
4. **Graceful Shutdown Risk:** `StopWorkerPool` waits indefinitely if workers are blocked

**Lines 369-373 - Shutdown:**
```go
func (s *cookService) StopWorkerPool() {
    s.logger.Info("Stopping worker pool")
    close(s.stopChan)
    s.wg.Wait()  // ⚠️ May hang if workers are blocked
    s.logger.Info("Worker pool stopped")
}
```

#### Recommended Fix

**Step 1: Add context with cancellation**

```go
type cookService struct {
    // ... existing fields ...
    ctx        context.Context    // Add worker context
    cancelFunc context.CancelFunc // Add cancel function
}

func NewCookService(...) CookService {
    ctx, cancel := context.WithCancel(context.Background())
    return &cookService{
        // ... existing initialization ...
        ctx:        ctx,
        cancelFunc: cancel,
    }
}
```

**Step 2: Update worker loop**

```go
go func() {
    defer s.wg.Done()
    s.logger.Info("Worker started for cook %d", cookID)

    for {
        select {
        case <-worker.stopChan:
            s.logger.Info("Worker stopped for cook %d", cookID)
            return
        case <-s.stopChan:
            s.logger.Info("Worker stopped for cook %d (global stop)", cookID)
            return
        case <-s.ctx.Done():  // Add context cancellation
            s.logger.Info("Worker stopped for cook %d (context cancelled)", cookID)
            return
        default:
            // Use service context instead of passed context
            _, err := s.AcceptOrder(s.ctx, cookID)
            if err != nil {
                time.Sleep(100 * time.Millisecond)
            }
        }
    }
}()
```

**Step 3: Update StopWorkerPool with timeout**

```go
func (s *cookService) StopWorkerPool() {
    s.logger.Info("Stopping worker pool")

    // Cancel context first
    s.cancelFunc()

    // Close stop channel
    close(s.stopChan)

    // Wait with timeout
    done := make(chan struct{})
    go func() {
        s.wg.Wait()
        close(done)
    }()

    select {
    case <-done:
        s.logger.Info("Worker pool stopped gracefully")
    case <-time.After(30 * time.Second):
        s.logger.Error("Worker pool shutdown timeout - some workers may still be running")
    }
}
```

#### Technical Debt Impact

- **Resource Leaks:** Goroutines may not terminate, leaking memory
- **Shutdown Hangs:** Application may hang during graceful shutdown
- **Testing:** Integration tests may timeout or hang
- **Production Stability:** May require forced restarts instead of graceful deployments

---

### 5. Database Migration Issues - Missing Down Migrations

**Severity:** HIGH
**Category:** Database Migration Correctness
**Impact:** Cannot rollback database changes, risky deployments

#### Issue Description

The database migration file `001_create_schema.sql` only contains UP migration (schema creation) without a corresponding DOWN migration (rollback). This violates migration best practices and creates risk for production deployments.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\migrations\001_create_schema.sql`

#### Problems Identified

1. **No Rollback Capability:** Cannot undo migrations if deployment fails
2. **Single File Design:** UP and DOWN migrations should be separate or clearly delimited
3. **Migration Tool Mismatch:** Using `psql -f` instead of proper migration tool (golang-migrate, goose, etc.)
4. **No Version Tracking:** No schema_migrations table to track applied migrations

**Makefile Line 47-48:**
```makefile
migrate-up:
    @echo "Running database migrations..."
    psql -h localhost -p 7001 -U postgres -d mcmocknald -f migrations/001_create_schema.sql
```

#### Additional Migration Issues

**Line 2-8 - Non-idempotent constraints:**
```sql
CREATE TABLE IF NOT EXISTS role (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) NOT NULL UNIQUE,  -- ⚠️ UNIQUE constraint may fail on re-run
    ...
);
```

**Lines 72-76 - Data seeding in schema migration:**
```sql
INSERT INTO role (name, created_at, modified_at) VALUES
    ('Regular Customer', NOW(), NOW()),
    ('VIP Customer', NOW(), NOW()),
    ('Cook', NOW(), NOW())
ON CONFLICT (name) DO NOTHING;  -- Good: uses ON CONFLICT
```

**Lines 78-84 - Seed data without conflict handling:**
```sql
INSERT INTO "user" (name, role, created_at, modified_at) VALUES
    ('Regular Customer 1', 'Regular Customer', NOW(), NOW()),
    ...
-- ⚠️ No ON CONFLICT - will fail if re-run
```

#### Recommended Fix

**Option 1: Use golang-migrate (Recommended)**

```bash
# Install golang-migrate
go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@latest

# Create separate UP/DOWN migrations
migrate create -ext sql -dir migrations -seq create_schema
```

Create two files:
- `migrations/000001_create_schema.up.sql`
- `migrations/000001_create_schema.down.sql`

**Down Migration (000001_create_schema.down.sql):**
```sql
-- Drop tables in reverse order (respecting foreign keys)
DROP TABLE IF EXISTS order_food CASCADE;
DROP TABLE IF EXISTS "order" CASCADE;
DROP TABLE IF EXISTS food CASCADE;
DROP TABLE IF EXISTS "user" CASCADE;
DROP TABLE IF EXISTS role CASCADE;

-- Drop indexes (automatically dropped with tables, but explicit is clear)
DROP INDEX IF EXISTS idx_order_food_food_id;
DROP INDEX IF EXISTS idx_order_food_order_id;
DROP INDEX IF EXISTS idx_order_created_at;
DROP INDEX IF EXISTS idx_order_ordered_by;
DROP INDEX IF EXISTS idx_order_assigned_cook;
DROP INDEX IF EXISTS idx_order_status;
DROP INDEX IF EXISTS idx_food_type;
DROP INDEX IF EXISTS idx_user_deleted_at;
DROP INDEX IF EXISTS idx_user_role;
DROP INDEX IF EXISTS idx_role_name;
```

**Update Makefile:**
```makefile
migrate-up:
    @echo "Running database migrations..."
    migrate -path migrations -database "postgresql://postgres:postgres@localhost:7001/mcmocknald?sslmode=disable" up

migrate-down:
    @echo "Rolling back database migrations..."
    migrate -path migrations -database "postgresql://postgres:postgres@localhost:7001/mcmocknald?sslmode=disable" down

migrate-status:
    @echo "Checking migration status..."
    migrate -path migrations -database "postgresql://postgres:postgres@localhost:7001/mcmocknald?sslmode=disable" version
```

**Option 2: Separate seed data from schema**

Create:
- `migrations/001_create_schema.sql` (schema only)
- `migrations/002_seed_data.sql` (seed data only)

**Fix seed data idempotency:**
```sql
-- In 002_seed_data.sql
INSERT INTO "user" (name, role, created_at, modified_at) VALUES
    ('Regular Customer 1', 'Regular Customer', NOW(), NOW()),
    ('Regular Customer 2', 'Regular Customer', NOW(), NOW()),
    ('VIP Customer 1', 'VIP Customer', NOW(), NOW()),
    ('VIP Customer 2', 'VIP Customer', NOW(), NOW()),
    ('Cook Bot 1', 'Cook', NOW(), NOW())
ON CONFLICT ON CONSTRAINT user_pkey DO NOTHING;  -- Add conflict handling

-- Better: Use explicit IDs and check existence
INSERT INTO "user" (id, name, role, created_at, modified_at)
SELECT 1, 'Regular Customer 1', 'Regular Customer', NOW(), NOW()
WHERE NOT EXISTS (SELECT 1 FROM "user" WHERE id = 1);
```

#### Technical Debt Impact

- **Deployment Risk:** Cannot rollback failed migrations in production
- **Testing:** Difficult to reset test databases cleanly
- **Development:** Developers cannot easily rollback local schema changes
- **CI/CD:** Migration failures require manual database cleanup

---

## MEDIUM PRIORITY ISSUES

### 6. Performance - Inefficient Queue Memory Usage

**Severity:** MEDIUM
**Category:** Performance / Memory
**Impact:** O(n) slice reallocation on dequeue, memory fragmentation

#### Issue Description

The priority queue implementation uses slice re-slicing for dequeue operations, which doesn't release memory and can cause memory fragmentation over time. With high-throughput scenarios (15,000 customers placing orders), this could lead to unbounded memory growth.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\pkg\queue\priority_queue.go`

**Lines 84-105 - Dequeue Implementation:**
```go
func (pq *PriorityQueue) Dequeue() (*domain.Order, error) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    if pq.size == 0 {
        return nil, ErrEmptyQueue
    }

    var order *domain.Order

    // VIP orders have priority
    if len(pq.vipOrders) > 0 {
        order = pq.vipOrders[0]
        pq.vipOrders = pq.vipOrders[1:]  // ⚠️ Memory not released
    } else if len(pq.regularOrders) > 0 {
        order = pq.regularOrders[0]
        pq.regularOrders = pq.regularOrders[1:]  // ⚠️ Memory not released
    }

    pq.size--
    return order, nil
}
```

#### Problem Analysis

**Memory Behavior:**
```go
// After 1000 dequeues with slice re-slicing:
// Slice still holds capacity for 1000 elements, but only using positions [1000:]
// Garbage collector cannot reclaim first 1000 positions

// Example:
orders := make([]*Order, 0, 1000)  // Capacity 1000
// ... add 1000 orders ...
orders = orders[1:]  // Length 999, but capacity still 1000
// First element memory not released!
```

**Test Scenario Impact:**
- Scenario 1: 150 orders/second × 180 seconds = 27,000 orders → Significant memory waste
- Scenario 2: 15,000 orders/second × 180 seconds = 2,700,000 orders → Severe memory bloat

#### Recommended Fix

**Approach 1: Implement Circular Buffer (Optimal for throughput)**

```go
type PriorityQueue struct {
    vipOrders     []*domain.Order
    vipHead       int  // Head index for circular buffer
    vipTail       int  // Tail index for circular buffer

    regularOrders []*domain.Order
    regularHead   int
    regularTail   int

    mu            sync.RWMutex
    size          int
}

func (pq *PriorityQueue) Dequeue() (*domain.Order, error) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    if pq.size == 0 {
        return nil, ErrEmptyQueue
    }

    var order *domain.Order

    if pq.vipHead != pq.vipTail {  // VIP queue has items
        order = pq.vipOrders[pq.vipHead]
        pq.vipOrders[pq.vipHead] = nil  // Release reference for GC
        pq.vipHead = (pq.vipHead + 1) % len(pq.vipOrders)
    } else if pq.regularHead != pq.regularTail {
        order = pq.regularOrders[pq.regularHead]
        pq.regularOrders[pq.regularHead] = nil  // Release reference for GC
        pq.regularHead = (pq.regularHead + 1) % len(pq.regularOrders)
    }

    pq.size--
    return order, nil
}
```

**Approach 2: Periodic slice reset (Simpler, acceptable for lower throughput)**

```go
func (pq *PriorityQueue) Dequeue() (*domain.Order, error) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    if pq.size == 0 {
        return nil, ErrEmptyQueue
    }

    var order *domain.Order

    if len(pq.vipOrders) > 0 {
        order = pq.vipOrders[0]
        pq.vipOrders[0] = nil  // Release reference for GC
        pq.vipOrders = pq.vipOrders[1:]

        // Reset slice if wasted capacity exceeds threshold
        if cap(pq.vipOrders)-len(pq.vipOrders) > 1000 {
            newSlice := make([]*domain.Order, len(pq.vipOrders))
            copy(newSlice, pq.vipOrders)
            pq.vipOrders = newSlice
        }
    } else if len(pq.regularOrders) > 0 {
        order = pq.regularOrders[0]
        pq.regularOrders[0] = nil  // Release reference for GC
        pq.regularOrders = pq.regularOrders[1:]

        // Reset slice if wasted capacity exceeds threshold
        if cap(pq.regularOrders)-len(pq.regularOrders) > 1000 {
            newSlice := make([]*domain.Order, len(pq.regularOrders))
            copy(newSlice, pq.regularOrders)
            pq.regularOrders = newSlice
        }
    }

    pq.size--
    return order, nil
}
```

**Approach 3: Use container/list (Simplest, slight performance trade-off)**

```go
import "container/list"

type PriorityQueue struct {
    vipOrders     *list.List  // Doubly-linked list
    regularOrders *list.List
    mu            sync.RWMutex
    size          int
}

func (pq *PriorityQueue) Dequeue() (*domain.Order, error) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    if pq.size == 0 {
        return nil, ErrEmptyQueue
    }

    var order *domain.Order

    if pq.vipOrders.Len() > 0 {
        elem := pq.vipOrders.Front()
        order = elem.Value.(*domain.Order)
        pq.vipOrders.Remove(elem)  // O(1) removal, automatic memory cleanup
    } else if pq.regularOrders.Len() > 0 {
        elem := pq.regularOrders.Front()
        order = elem.Value.(*domain.Order)
        pq.regularOrders.Remove(elem)
    }

    pq.size--
    return order, nil
}
```

#### Technical Debt Impact

- **Memory:** Unbounded growth in high-throughput scenarios
- **Performance:** Potential GC pressure from retained memory
- **Scalability:** Limits system capacity under load
- **Cost:** Higher memory footprint in cloud deployments

---

### 7. Performance - Missing Database Indexes on Status Queries

**Severity:** MEDIUM
**Category:** Performance / Database
**Impact:** O(n) sequential scan on frequently queried status field combinations

#### Issue Description

The database migration creates indexes on individual columns but **misses composite indexes** for common query patterns, leading to inefficient query plans for status-based queries with additional filters.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\migrations\001_create_schema.sql`

**Lines 51-55 - Existing Indexes:**
```sql
CREATE INDEX idx_order_status ON "order"(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_order_assigned_cook ON "order"(assigned_cook_user) WHERE deleted_at IS NULL;
CREATE INDEX idx_order_ordered_by ON "order"(ordered_by) WHERE deleted_at IS NULL;
CREATE INDEX idx_order_created_at ON "order"(created_at DESC);
```

#### Missing Index Scenarios

**Query 1: Get serving orders by cook (cook_service.go:128)**
```sql
-- From GetByCookID query
SELECT * FROM "order"
WHERE assigned_cook_user = $1  -- Uses idx_order_assigned_cook
-- But also filters on status implicitly when processing SERVING orders
```

**Query 2: Get pending orders for requeue (order_repository.go:315-318)**
```sql
SELECT * FROM "order"
WHERE status = $1 AND deleted_at IS NULL
ORDER BY id
-- Uses idx_order_status
-- But could benefit from composite index with created_at for FIFO ordering
```

**Query 3: Stats query (order_repository.go:324-330)**
```sql
SELECT
    COUNT(CASE WHEN status = $1 THEN 1 END) as completed,
    COUNT(CASE WHEN status != $1 THEN 1 END) as incomplete
FROM "order"
WHERE deleted_at IS NULL
-- Sequential scan on entire table!
```

#### Recommended Fix

**Add composite indexes:**

```sql
-- Composite index for status + created_at (FIFO ordering)
CREATE INDEX idx_order_status_created
ON "order"(status, created_at DESC)
WHERE deleted_at IS NULL;

-- Composite index for cook assignment + status (worker queries)
CREATE INDEX idx_order_cook_status
ON "order"(assigned_cook_user, status)
WHERE deleted_at IS NULL AND assigned_cook_user IS NOT NULL;

-- Composite index for customer + status (customer order history)
CREATE INDEX idx_order_customer_status
ON "order"(ordered_by, status)
WHERE deleted_at IS NULL;

-- Covering index for stats query
CREATE INDEX idx_order_stats
ON "order"(status)
WHERE deleted_at IS NULL;
```

**Verify with EXPLAIN ANALYZE:**

```sql
-- Test query performance
EXPLAIN ANALYZE
SELECT * FROM "order"
WHERE status = 'PENDING' AND deleted_at IS NULL
ORDER BY created_at DESC
LIMIT 100;

-- Should show: Index Scan using idx_order_status_created
-- Instead of: Seq Scan on "order"
```

#### Technical Debt Impact

- **Performance:** Query time degrades linearly with data growth (O(n) instead of O(log n))
- **Scalability:** Cannot handle high-volume production workloads efficiently
- **Resource Usage:** Higher CPU and I/O from sequential scans
- **Response Time:** Slower API responses under load

---

### 8. Security - Missing Input Validation on Food IDs

**Severity:** MEDIUM
**Category:** Security / Input Validation
**Impact:** Potential for invalid data insertion, database constraint violations

#### Issue Description

The order creation endpoint accepts `food_ids` array but **does not validate** that the food IDs exist or are valid before attempting database insertion. This can lead to cryptic database errors instead of clear validation messages.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\order_service.go`

**Lines 60-106 - CreateOrder:**
```go
func (s *orderService) CreateOrder(ctx context.Context, customerID int, foodIDs []int) (*domain.Order, error) {
    // Validates customer exists ✓
    customer, err := s.userRepo.GetByID(ctx, customerID)
    if err != nil {
        return nil, fmt.Errorf("customer not found: %w", err)
    }

    // Validates customer is not deleted ✓
    if customer.IsDeleted() {
        return nil, fmt.Errorf("customer is deleted")
    }

    // Validates customer role ✓
    if !customer.IsCustomer() {
        return nil, fmt.Errorf("user is not a customer")
    }

    // ⚠️ MISSING: Validates food IDs exist and are valid

    // Creates order with potentially invalid food IDs
    createdOrder, err := s.orderRepo.Create(ctx, order, foodIDs)
    if err != nil {
        // Database error instead of validation error
        return nil, fmt.Errorf("failed to create order: %w", err)
    }
    // ...
}
```

**Handler Layer (order_handler.go:41-55):**
```go
type CreateOrderRequest struct {
    CustomerID int   `json:"customer_id" binding:"required"`
    FoodIDs    []int `json:"food_ids" binding:"required,min=1"`  // Only validates non-empty ⚠️
}
```

#### Security & UX Issues

1. **No Food Existence Check:** Food IDs could reference non-existent items
2. **No Soft-Delete Check:** Food IDs could reference deleted food items
3. **Poor Error Messages:** Database foreign key errors instead of user-friendly validation
4. **Potential for Empty Orders:** No check for empty food list (though handler has min=1)
5. **No Duplicate Detection:** Same food ID could appear multiple times

#### Recommended Fix

**Step 1: Add validation in service layer**

```go
func (s *orderService) CreateOrder(ctx context.Context, customerID int, foodIDs []int) (*domain.Order, error) {
    // Existing customer validation...

    // NEW: Validate food IDs
    if err := s.validateFoodIDs(ctx, foodIDs); err != nil {
        return nil, err
    }

    // Continue with order creation...
}

// NEW: Food validation method
func (s *orderService) validateFoodIDs(ctx context.Context, foodIDs []int) error {
    if len(foodIDs) == 0 {
        return fmt.Errorf("order must contain at least one food item")
    }

    // Check for duplicates
    seen := make(map[int]bool)
    for _, id := range foodIDs {
        if seen[id] {
            return fmt.Errorf("duplicate food ID in order: %d", id)
        }
        seen[id] = true
    }

    // Validate each food ID exists and is not deleted
    for _, foodID := range foodIDs {
        food, err := s.foodRepo.GetByID(ctx, foodID)
        if err != nil {
            return fmt.Errorf("food item not found: %d", foodID)
        }
        if food.IsDeleted() {
            return fmt.Errorf("food item is no longer available: %s", food.Name)
        }
    }

    return nil
}
```

**Step 2: Add service dependency (food repository)**

```go
type orderService struct {
    orderRepo       domain.OrderRepository
    userRepo        domain.UserRepository
    foodRepo        domain.FoodRepository  // ADD THIS
    orderQueue      queue.OrderQueue
    logger          logger.Logger
    servingDuration time.Duration
}

func NewOrderService(
    orderRepo domain.OrderRepository,
    userRepo domain.UserRepository,
    foodRepo domain.FoodRepository,  // ADD THIS
    orderQueue queue.OrderQueue,
    log logger.Logger,
    servingDuration time.Duration,
) OrderService {
    return &orderService{
        orderRepo:       orderRepo,
        userRepo:        userRepo,
        foodRepo:        foodRepo,  // ADD THIS
        orderQueue:      orderQueue,
        logger:          log,
        servingDuration: servingDuration,
    }
}
```

**Step 3: Update main.go constructor call**

```go
// In cmd/api/main.go:143
orderService := service.NewOrderService(
    orderRepo,
    userRepo,
    foodRepo,  // ADD THIS
    orderQueue,
    appLogger,
    cfg.OrderServingDuration,
)
```

**Step 4: Improve handler validation**

```go
type CreateOrderRequest struct {
    CustomerID int   `json:"customer_id" binding:"required,min=1"`
    FoodIDs    []int `json:"food_ids" binding:"required,min=1,dive,min=1"`
    // dive - validates each element
    // min=1 - ensures food IDs are positive
}
```

#### Technical Debt Impact

- **Security:** Potential for invalid data insertion
- **User Experience:** Cryptic database errors instead of clear messages
- **Data Integrity:** Orphaned order-food relationships possible
- **Debugging:** Harder to diagnose why order creation fails

---

### 9. Tight Coupling - Service Layer Directly Spawning Goroutines

**Severity:** MEDIUM
**Category:** Tight Coupling / Concurrency
**Impact:** Service layer handling infrastructure concerns, hard to test

#### Issue Description

The `CookService.AcceptOrder` method directly spawns a goroutine for order processing, mixing business logic with concurrency infrastructure. This violates separation of concerns and makes testing difficult.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\cook_service.go`

**Lines 268-272:**
```go
func (s *cookService) AcceptOrder(ctx context.Context, cookID int) (*domain.Order, error) {
    // ... order assignment logic ...

    // ⚠️ Service layer spawning goroutine for infrastructure concern
    go s.processOrder(ctx, order.ID, cookID)

    return order, nil
}
```

**Lines 274-287:**
```go
// processOrder is called in goroutine, no way to track completion or errors
func (s *cookService) processOrder(ctx context.Context, orderID, cookID int) {
    // Simulate cooking time
    time.Sleep(s.servingDuration)

    // Update order status - errors only logged, not returned ⚠️
    if err := s.orderRepo.UpdateStatus(ctx, orderID, domain.OrderStatusComplete); err != nil {
        s.logger.Error("Failed to complete order %d: %v", orderID, err)
        return
    }

    s.logger.Info("Order %d completed by cook %d", orderID, cookID)
}
```

#### Problems Identified

1. **No Error Propagation:** Goroutine errors only logged, not surfaced to caller
2. **Testing Difficulty:** Cannot verify order completion in tests (timing-dependent)
3. **No Completion Tracking:** Caller has no way to know when order is done
4. **Shutdown Risk:** Fire-and-forget goroutines may not complete during shutdown
5. **SRP Violation:** Service layer managing concurrency instead of just business logic

#### Recommended Fix

**Approach 1: Return completion channel (Preferred for testability)**

```go
func (s *cookService) AcceptOrder(ctx context.Context, cookID int) (*domain.Order, <-chan error) {
    // ... existing assignment logic ...

    // Create completion channel
    done := make(chan error, 1)

    // Process in goroutine but return channel for tracking
    go func() {
        done <- s.processOrder(ctx, order.ID, cookID)
        close(done)
    }()

    return order, done
}

// processOrder now returns error for proper handling
func (s *cookService) processOrder(ctx context.Context, orderID, cookID int) error {
    // Simulate cooking time (with context cancellation support)
    timer := time.NewTimer(s.servingDuration)
    defer timer.Stop()

    select {
    case <-timer.C:
        // Cooking complete
    case <-ctx.Done():
        return ctx.Err()
    }

    // Update order status
    if err := s.orderRepo.UpdateStatus(ctx, orderID, domain.OrderStatusComplete); err != nil {
        s.logger.Error("Failed to complete order %d: %v", orderID, err)
        return fmt.Errorf("failed to complete order: %w", err)
    }

    s.logger.Info("Order %d completed by cook %d", orderID, cookID)
    return nil
}
```

**Approach 2: Use worker pool pattern more cleanly (Alternative)**

```go
// Add order to processing queue instead of spawning goroutine
func (s *cookService) AcceptOrder(ctx context.Context, cookID int) (*domain.Order, error) {
    // ... existing assignment logic ...

    // Add to processing queue (tracked by worker pool)
    s.processingQueue <- OrderTask{
        OrderID: order.ID,
        CookID:  cookID,
        StartTime: time.Now(),
    }

    return order, nil
}

// Single dedicated goroutine per cook processes tasks
func (s *cookService) processOrderWorker(ctx context.Context, cookID int) {
    for {
        select {
        case task := <-s.processingQueue:
            if err := s.processOrder(ctx, task.OrderID, task.CookID); err != nil {
                s.logger.Error("Order processing failed: %v", err)
                // Could retry or move to dead letter queue
            }
        case <-ctx.Done():
            return
        }
    }
}
```

**Testing Impact:**

```go
// With completion channel, tests can verify completion
func TestAcceptOrder_CompletesSuccessfully(t *testing.T) {
    // ... setup ...

    order, done := cookService.AcceptOrder(ctx, cookID)
    assert.NotNil(t, order)

    // Wait for completion with timeout
    select {
    case err := <-done:
        assert.NoError(t, err)
    case <-time.After(15 * time.Second):
        t.Fatal("Order processing timeout")
    }

    // Verify order status
    updatedOrder, _ := orderRepo.GetByID(ctx, order.ID)
    assert.Equal(t, domain.OrderStatusComplete, updatedOrder.Status)
}
```

#### Technical Debt Impact

- **Testing:** Cannot verify order completion reliably
- **Error Handling:** Silent failures in background processing
- **Monitoring:** No visibility into processing failures
- **Reliability:** Fire-and-forget pattern loses error information

---

### 10. Documentation - Missing Package-Level Documentation

**Severity:** MEDIUM
**Category:** Documentation Gaps
**Impact:** Reduced code discoverability and understanding for new developers

#### Issue Description

While individual functions have good GoDoc comments, **package-level documentation is missing** across all packages. This makes it harder for developers to understand the purpose and responsibilities of each package.

#### Missing Package Docs

**Affected Packages:**

1. `internal/domain` - No package doc explaining domain entities and repository interfaces
2. `internal/service` - No package doc explaining business logic layer
3. `internal/handler` - No package doc explaining HTTP handler layer
4. `internal/infrastructure/postgres` - No package doc explaining PostgreSQL implementation
5. `internal/infrastructure/memory` - No package doc explaining in-memory implementation
6. `pkg/queue` - No package doc explaining priority queue algorithm
7. `internal/config` - No package doc explaining configuration management
8. `internal/logger` - No package doc explaining logging strategy

#### Recommended Fix

**Example: internal/domain/doc.go (Create new file)**

```go
// Package domain contains the core domain entities and repository interfaces
// for the McMocknald Order Kiosk system.
//
// This package follows Clean Architecture principles where domain entities
// are independent of infrastructure concerns. All database access is abstracted
// through repository interfaces defined here and implemented in the
// infrastructure layer.
//
// # Entities
//
// The main entities are:
//   - User: Represents customers (Regular/VIP) and cook bots
//   - Order: Represents customer orders with status tracking
//   - Food: Represents menu items (Food/Drink/Dessert)
//   - Role: Represents user role types (deprecated, using RoleType instead)
//
// # Repository Interfaces
//
// Repository interfaces follow the Repository Pattern and Dependency Inversion:
//   - UserRepository: CRUD operations for users with soft-delete support
//   - OrderRepository: Order lifecycle management with cook assignment
//   - FoodRepository: Menu item management
//   - RoleRepository: Role management (rarely used)
//
// All repository methods are designed for O(1) or O(log n) complexity
// with appropriate database indexes.
//
// # Time Complexity
//
// Time complexity annotations are provided on all repository methods:
//   - O(1): In-memory map lookups, indexed database queries
//   - O(log n): Database lookups with B-tree indexes
//   - O(n): Full table scans (GetByStatus, GetStats, etc.)
package domain
```

**Example: pkg/queue/doc.go**

```go
// Package queue implements a hybrid priority + FIFO queue for order processing.
//
// The queue prioritizes VIP customer orders over Regular customer orders,
// while maintaining FIFO ordering within each priority level. This ensures
// VIP customers receive priority service without unfairly penalizing regular
// customers who ordered earlier.
//
// # Algorithm
//
// The implementation uses two separate FIFO queues:
//   - vipOrders: Queue for VIP customer orders (higher priority)
//   - regularOrders: Queue for Regular customer orders (lower priority)
//
// Dequeue operation checks VIP queue first, falling back to regular queue
// only when VIP queue is empty. This achieves O(1) enqueue and dequeue.
//
// # Concurrency
//
// All queue operations are thread-safe using sync.RWMutex. Multiple
// cook bots can safely dequeue orders concurrently while customer orders
// are being enqueued.
//
// # Time Complexity
//
//   - Enqueue: O(1) amortized (append to slice)
//   - Dequeue: O(1) (remove from front of slice)
//   - EnqueueAtFront: O(n) where n is queue size (rare operation)
//   - Size: O(1) (cached counter)
//   - IsEmpty: O(1) (cached counter)
//   - Peek: O(1) (no removal)
//
// # Usage Example
//
//	queue := queue.NewPriorityQueue()
//
//	// Enqueue VIP order
//	vipOrder := &domain.Order{
//	    ID: 1,
//	    CustomerRole: domain.RoleVIPCustomer,
//	}
//	queue.Enqueue(vipOrder)
//
//	// Enqueue Regular order
//	regularOrder := &domain.Order{
//	    ID: 2,
//	    CustomerRole: domain.RoleRegularCustomer,
//	}
//	queue.Enqueue(regularOrder)
//
//	// Dequeue (VIP order comes first)
//	order, err := queue.Dequeue()  // Returns vipOrder
package queue
```

**Example: internal/service/doc.go**

```go
// Package service implements the business logic layer of the McMocknald
// Order Kiosk system.
//
// This layer orchestrates domain entities and repositories to implement
// core business use cases such as order creation, cook assignment, and
// order processing.
//
// # Services
//
//   - OrderService: Manages order lifecycle and queue operations
//   - CookService: Manages cook bots and order processing
//
// # Design Patterns
//
// The service layer follows several design patterns:
//   - Dependency Injection: All dependencies injected via constructors
//   - Interface Segregation: Focused service interfaces
//   - Single Responsibility: Each service has one clear purpose
//
// # Worker Pool
//
// CookService implements a worker pool pattern where each cook bot
// runs in its own goroutine, continuously polling the queue for orders
// and processing them with configurable serving duration.
//
// The worker pool supports:
//   - Dynamic worker addition (new cook bots)
//   - Graceful worker removal (soft delete)
//   - Worker reinstatement (undo soft delete)
//   - Graceful shutdown (wait for in-flight orders)
package service
```

#### Additional Documentation Improvements

**Add examples to critical functions:**

```go
// Enqueue adds an order to the appropriate queue based on customer type.
// VIP orders go to vipOrders, Regular orders go to regularOrders.
//
// Time Complexity: O(1) - append operation is amortized O(1)
//
// Example:
//
//	order := &domain.Order{
//	    ID: 123,
//	    CustomerRole: domain.RoleVIPCustomer,
//	}
//	if err := queue.Enqueue(order); err != nil {
//	    log.Fatalf("Failed to enqueue: %v", err)
//	}
func (pq *PriorityQueue) Enqueue(order *domain.Order) error {
    // ... implementation ...
}
```

#### Technical Debt Impact

- **Onboarding:** Slower new developer onboarding
- **Discoverability:** Harder to understand package responsibilities
- **Maintenance:** Increased time to understand code before changes
- **Documentation:** Incomplete godoc.org / pkg.go.dev documentation

---

### 11. Testing - No Integration Tests for Database Mode

**Severity:** MEDIUM
**Category:** Testing Gaps
**Impact:** PostgreSQL implementation untested, potential production bugs

#### Issue Description

The test suite (`order_service_test.go`) only tests the **in-memory implementation**. The PostgreSQL repository implementation has **zero test coverage**, meaning database-specific bugs could reach production.

**File:** `C:\Users\KazLeowKeanTat\Downloads\Golang Projects\mcmocknald-order-kiosk-project\internal\service\order_service_test.go`

**Lines 34-36:**
```go
// Initialize repositories
userRepo := memory.NewUserRepository()     // ⚠️ Only memory mode tested
foodRepo := memory.NewFoodRepository()     // ⚠️ Only memory mode tested
orderRepo := memory.NewOrderRepository(userRepo, foodRepo)  // ⚠️ Only memory mode tested
```

#### Untested PostgreSQL Code

**All PostgreSQL repositories have zero test coverage:**

1. `internal/infrastructure/postgres/user_repository.go` - 223 lines untested
2. `internal/infrastructure/postgres/order_repository.go` - 357 lines untested
3. `internal/infrastructure/postgres/food_repository.go` - ~150 lines untested (estimated)
4. `internal/infrastructure/postgres/role_repository.go` - ~100 lines untested (estimated)
5. `internal/infrastructure/postgres/db.go` - 30 lines untested

**Total: ~860 lines of critical database code with no automated testing**

#### Potential Untested Issues

1. **SQL Syntax Errors:** Query syntax could be wrong but uncaught
2. **Transaction Handling:** Rollback behavior untested
3. **Foreign Key Constraints:** Constraint violations untested
4. **Concurrent Access:** Database-level locking untested
5. **Migration Compatibility:** Schema changes could break queries
6. **NULL Handling:** Nullable fields (*int, *time.Time) could cause issues

**Example from order_repository.go:114-116:**
```sql
WHERE of.order_id = $1 AND of.deleted_at IS NULL
-- ⚠️ This WHERE clause is never tested
-- Could be missing, wrong column name, or wrong logic
```

#### Recommended Fix

**Step 1: Create integration test file**

Create: `internal/infrastructure/postgres/order_repository_test.go`

```go
package postgres_test

import (
    "context"
    "database/sql"
    "testing"

    "github.com/stretchr/testify/assert"
    "github.com/stretchr/testify/require"
    "mcmocknald-order-kiosk/internal/domain"
    "mcmocknald-order-kiosk/internal/infrastructure/postgres"
)

func setupTestDB(t *testing.T) *sql.DB {
    // Use test database or docker container
    dsn := "host=localhost port=7001 user=postgres password=postgres dbname=mcmocknald_test sslmode=disable"
    db, err := postgres.NewDatabase(dsn)
    require.NoError(t, err)

    // Clean database before each test
    _, err = db.Exec("TRUNCATE TABLE order_food, \"order\", food, \"user\", role CASCADE")
    require.NoError(t, err)

    return db
}

func TestOrderRepository_Create(t *testing.T) {
    db := setupTestDB(t)
    defer db.Close()

    userRepo := postgres.NewUserRepository(db)
    foodRepo := postgres.NewFoodRepository(db)
    orderRepo := postgres.NewOrderRepository(db)

    // Create test customer
    customer := &domain.User{
        Name: "Test Customer",
        Role: domain.RoleRegularCustomer,
    }
    createdCustomer, err := userRepo.Create(context.Background(), customer)
    require.NoError(t, err)

    // Create test food
    food := &domain.Food{
        Name: "Burger",
        Type: domain.FoodTypeFood,
    }
    createdFood, err := foodRepo.Create(context.Background(), food)
    require.NoError(t, err)

    // Test order creation
    order := &domain.Order{
        Status:    domain.OrderStatusPending,
        OrderedBy: createdCustomer.ID,
    }
    createdOrder, err := orderRepo.Create(context.Background(), order, []int{createdFood.ID})

    assert.NoError(t, err)
    assert.NotZero(t, createdOrder.ID)
    assert.Equal(t, domain.OrderStatusPending, createdOrder.Status)
}

func TestOrderRepository_GetByID_WithFoods(t *testing.T) {
    // Test that GetByID correctly joins food items
    // This tests the SQL JOIN logic that's currently untested
}

func TestOrderRepository_AssignCook(t *testing.T) {
    // Test cook assignment updates
}

func TestOrderRepository_UpdateStatus(t *testing.T) {
    // Test status transitions
}

func TestOrderRepository_GetStats(t *testing.T) {
    // Test aggregation query
}
```

**Step 2: Add Docker compose for test database**

Create: `docker-compose.test.yml`

```yaml
version: '3.8'
services:
  test-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: mcmocknald_test
    ports:
      - "7002:5432"
    tmpfs:
      - /var/lib/postgresql/data  # In-memory for faster tests
```

**Step 3: Add test runner to Makefile**

```makefile
test-integration:
    @echo "Starting test database..."
    docker-compose -f docker-compose.test.yml up -d
    @echo "Waiting for database..."
    sleep 3
    @echo "Running migrations..."
    psql -h localhost -p 7002 -U postgres -d mcmocknald_test -f migrations/001_create_schema.sql
    @echo "Running integration tests..."
    go test -v ./internal/infrastructure/postgres/...
    @echo "Stopping test database..."
    docker-compose -f docker-compose.test.yml down

test-all: test test-integration
```

**Step 4: Add test coverage reporting**

```makefile
test-coverage:
    @echo "Running tests with coverage..."
    go test -coverprofile=coverage.out ./...
    go tool cover -html=coverage.out -o coverage.html
    @echo "Coverage report: coverage.html"
    go tool cover -func=coverage.out | grep total
```

#### Technical Debt Impact

- **Production Bugs:** Database-specific bugs only found in production
- **Regression Risk:** Changes to PostgreSQL code have no safety net
- **Confidence:** Cannot confidently deploy database mode
- **Debugging:** Harder to diagnose production database issues

---

## LOW PRIORITY ISSUES

### 12. Code Quality - Magic Numbers in Configuration

**Severity:** LOW
**Category:** Maintainability
**Impact:** Hardcoded values reduce configuration flexibility

#### Issue Description

Several timeout and capacity values are hardcoded as magic numbers instead of being configurable, reducing flexibility for different environments.

**Affected Files:**

**1. pkg/queue/priority_queue.go:53-54**
```go
vipOrders:     make([]*domain.Order, 0, 1000),     // ⚠️ Hardcoded capacity
regularOrders: make([]*domain.Order, 0, 1000),     // ⚠️ Hardcoded capacity
```

**2. internal/infrastructure/postgres/db.go:24-26**
```go
db.SetMaxOpenConns(100)    // ⚠️ Hardcoded connection pool size
db.SetMaxIdleConns(10)     // ⚠️ Hardcoded idle connections
db.SetConnMaxLifetime(0)   // ⚠️ Connections never expire
```

**3. internal/service/cook_service.go:347**
```go
time.Sleep(100 * time.Millisecond)  // ⚠️ Hardcoded poll interval
```

**4. cmd/api/main.go:89**
```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)  // ⚠️ Hardcoded shutdown timeout
```

#### Recommended Fix

**Add to Config struct:**

```go
type Config struct {
    // ... existing fields ...

    // Queue Configuration
    QueueInitialCapacity int

    // Database Connection Pool
    DBMaxOpenConns    int
    DBMaxIdleConns    int
    DBConnMaxLifetime time.Duration

    // Worker Configuration
    WorkerPollInterval    time.Duration
    ShutdownTimeout       time.Duration
}

func Load() (*Config, error) {
    // ... existing code ...

    config := &Config{
        // ... existing fields ...

        QueueInitialCapacity:  getIntEnv("QUEUE_INITIAL_CAPACITY", 1000),
        DBMaxOpenConns:        getIntEnv("DB_MAX_OPEN_CONNS", 100),
        DBMaxIdleConns:        getIntEnv("DB_MAX_IDLE_CONNS", 10),
        DBConnMaxLifetime:     getDurationEnv("DB_CONN_MAX_LIFETIME", 0),
        WorkerPollInterval:    getDurationEnv("WORKER_POLL_INTERVAL", 100*time.Millisecond),
        ShutdownTimeout:       getDurationEnv("SHUTDOWN_TIMEOUT", 30*time.Second),
    }

    return config, nil
}
```

**Update .env.example:**

```env
# Queue Configuration
QUEUE_INITIAL_CAPACITY=1000

# Database Connection Pool (for database mode)
DB_MAX_OPEN_CONNS=100
DB_MAX_IDLE_CONNS=10
DB_CONN_MAX_LIFETIME=0  # 0 = no expiration

# Worker Configuration
WORKER_POLL_INTERVAL=100ms
SHUTDOWN_TIMEOUT=30s
```

#### Technical Debt Impact

- **Flexibility:** Cannot tune performance for different environments
- **Scalability:** Cannot adjust pool sizes for high load
- **Operations:** Requires code changes to adjust operational parameters

---

### 13. Code Quality - Inconsistent Error Wrapping

**Severity:** LOW
**Category:** Maintainability / Error Handling
**Impact:** Inconsistent error messages, harder debugging

#### Issue Description

Error wrapping is inconsistent across the codebase. Some functions use `fmt.Errorf` with `%w`, others use `%v`, and some don't wrap errors at all.

**Examples:**

**Good error wrapping (order_service.go:65):**
```go
return nil, fmt.Errorf("customer not found: %w", err)  // ✓ Uses %w for wrapping
```

**Inconsistent error wrapping (cook_service.go:97):**
```go
return nil, fmt.Errorf("failed to create cook: %w", err)  // ✓ Good
// But later...
return fmt.Errorf("cook not found: %w", err)             // ✓ Good
// But later...
s.logger.Error("Failed to get orders for cook %d: %v", cookID, err)  // ⚠️ Uses %v in logging
```

**Missing context (postgres/order_repository.go:104):**
```go
if err != nil {
    return nil, fmt.Errorf("failed to get order: %w", err)
    // ⚠️ Missing order ID context
}
// Better:
return nil, fmt.Errorf("failed to get order %d: %w", id, err)
```

#### Recommended Fix

**Establish error wrapping guidelines:**

1. **Always use `%w` for wrapping errors:**
   ```go
   return fmt.Errorf("operation failed: %w", err)
   ```

2. **Include relevant context:**
   ```go
   return fmt.Errorf("failed to update order %d: %w", orderID, err)
   ```

3. **Use structured logging for error details:**
   ```go
   s.logger.Error("Failed to update order: orderID=%d error=%v", orderID, err)
   ```

4. **Create sentinel errors for expected conditions:**
   ```go
   var (
       ErrOrderNotFound   = errors.New("order not found")
       ErrCookNotFound    = errors.New("cook not found")
       ErrInvalidCustomer = errors.New("invalid customer")
   )
   ```

#### Technical Debt Impact

- **Debugging:** Harder to trace error origins
- **Monitoring:** Inconsistent error patterns in logs
- **User Experience:** Less helpful error messages

---

### 14. Documentation - Missing API Examples in Godoc

**Severity:** LOW
**Category:** Documentation
**Impact:** Reduced developer productivity, more support questions

#### Issue Description

While handlers have Swagger annotations, there are **no runnable examples** in GoDoc format. This makes it harder for developers to understand how to use the API programmatically.

**Handler files have Swagger comments but no Go examples:**

**order_handler.go:30-40:**
```go
// @Summary Create a new order
// @Description Create a new order for a customer (Regular or VIP)
// @Tags orders
// @Accept json
// @Produce json
// @Param request body CreateOrderRequest true "Order creation request"
// @Success 201 {object} domain.Order
// @Failure 400 {object} ErrorResponse
// @Failure 500 {object} ErrorResponse
// @Router /api/orders [post]
```

#### Recommended Fix

**Add example functions to handler files:**

Create: `internal/handler/examples_test.go`

```go
package handler_test

import (
    "bytes"
    "encoding/json"
    "net/http"
    "net/http/httptest"
    "testing"

    "github.com/gin-gonic/gin"
    "mcmocknald-order-kiosk/internal/handler"
)

// ExampleCreateOrder demonstrates how to create an order via the API
func ExampleOrderHandler_CreateOrder() {
    // Create request
    requestBody := map[string]interface{}{
        "customer_id": 1,
        "food_ids":    []int{1, 2, 3},
    }

    jsonBody, _ := json.Marshal(requestBody)

    req := httptest.NewRequest(http.MethodPost, "/api/orders", bytes.NewBuffer(jsonBody))
    req.Header.Set("Content-Type", "application/json")

    w := httptest.NewRecorder()

    // ... handler execution ...

    // Expected response: 201 Created with order details
}

// ExampleCookHandler_AcceptOrder demonstrates how a cook accepts an order
func ExampleCookHandler_AcceptOrder() {
    req := httptest.NewRequest(http.MethodPost, "/api/cooks/1/accept", nil)
    w := httptest.NewRecorder()

    // ... handler execution ...

    // Expected response: 200 OK with accepted order details
}
```

**Add usage examples to README.md:**

````markdown
## API Usage Examples

### Create an Order

```bash
curl -X POST http://localhost:8080/api/orders \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": 1,
    "food_ids": [1, 2, 3]
  }'
```

Response:
```json
{
  "id": 1,
  "status": "PENDING",
  "ordered_by": 1,
  "customer_name": "VIP Customer 1",
  "customer_role": "VIP Customer",
  "created_at": "2025-10-24T02:15:05Z"
}
```
````

#### Technical Debt Impact

- **Developer Experience:** Harder to learn and use the API
- **Documentation Quality:** Incomplete API documentation
- **Support Overhead:** More questions about API usage

---

## Summary by Severity

### CRITICAL (1 issue) - Build Blockers
1. **Import Path Mismatch** - Complete build failure across 14 files

### HIGH (4 issues) - Production Blockers
2. **Credential Exposure** - .env file with database credentials
3. **Tight Coupling** - Repository dependencies violating patterns
4. **Missing Context Cancellation** - Goroutine leak risk in worker pool
5. **Missing Down Migrations** - Cannot rollback database changes

### MEDIUM (6 issues) - Technical Debt
6. **Inefficient Queue Memory** - O(n) memory waste on dequeue
7. **Missing Database Indexes** - Performance degradation on common queries
8. **Missing Input Validation** - Food IDs not validated before insertion
9. **Service Layer Goroutines** - Mixed concerns, hard to test
10. **Missing Package Documentation** - Poor code discoverability
11. **No Integration Tests** - PostgreSQL code has zero test coverage

### LOW (3 issues) - Code Quality
12. **Magic Numbers** - Hardcoded configuration values
13. **Inconsistent Error Wrapping** - Mixed error handling patterns
14. **Missing API Examples** - Incomplete documentation

---

## Recommendations Prioritized

### Immediate (Before Any Deployment)

1. **FIX CRITICAL BUILD ISSUE** - Update import paths OR go.mod module name
2. **Verify Credentials** - Ensure .env never committed to git history
3. **Add Down Migrations** - Implement rollback capability
4. **Add Context Cancellation** - Fix worker pool shutdown

### Before Production (High Priority)

5. **Decouple Repositories** - Move enrichment to service layer
6. **Add Database Indexes** - Implement composite indexes for query performance
7. **Add Input Validation** - Validate food IDs in order creation
8. **Create Integration Tests** - Test PostgreSQL implementations

### Technical Debt Reduction (Medium Priority)

9. **Optimize Queue Memory** - Implement circular buffer or periodic reset
10. **Refactor Service Concurrency** - Return completion channels
11. **Add Package Documentation** - Create doc.go files for all packages
12. **Externalize Magic Numbers** - Move to configuration

### Code Quality Improvements (Low Priority)

13. **Standardize Error Handling** - Consistent error wrapping patterns
14. **Add API Examples** - GoDoc examples and README snippets

---

## Approval Status

**REQUIRES CHANGES** - Critical build-blocking issues must be resolved before deployment.

The codebase demonstrates excellent architectural design with Clean Architecture, SOLID principles, and proper abstraction patterns. However, the **critical import path mismatch completely prevents compilation**, and several high-priority issues create production risks.

**Recommended Actions:**

1. **Immediate:** Fix import path mismatch (choose Option 1 or 2 from recommendations)
2. **Before Merge:** Address all HIGH priority issues
3. **Before Production:** Address all MEDIUM priority issues
4. **Technical Debt Sprint:** Address LOW priority issues

**Once the CRITICAL and HIGH priority issues are resolved, this codebase will be production-ready with only manageable technical debt remaining.**

---

## Appendix: File Reference

### Files Reviewed
- Total Go files: 23
- Total lines of code: ~3,500
- Test files: 1
- Migration files: 1
- Configuration files: 4

### Critical Files
1. `go.mod` - Module definition
2. `.env` / `.env.example` - Configuration and credentials
3. All files with import statements (14 files)
4. `migrations/001_create_schema.sql` - Database schema
5. `internal/service/cook_service.go` - Worker pool implementation
6. `pkg/queue/priority_queue.go` - Core queue algorithm

---

**End of Technical Debt Review**

**Reviewer:** Claude Code (Technical Debt Sub-Agent)
**Date:** 2025-10-24
**Time:** 02:15:05
